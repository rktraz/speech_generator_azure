{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-speech\n",
      "  Downloading azure_cognitiveservices_speech-1.29.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-cognitiveservices-speech\n",
      "Successfully installed azure-cognitiveservices-speech-1.29.0\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Synthesis Using the Speech SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up some general items. Import the Speech SDK Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the subscription info for the Speech Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "subscription_key = os.getenv('SUBSCRIPTION_KEY')\n",
    "service_region = os.getenv('SERVICE_REGION')\n",
    "translator_endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=service_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading voice parameters from SSML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssml_string = open(\"ssml_test.xml\", \"r\").read()\n",
    "result = speech_synthesizer.speak_ssml_async(ssml_string).get()\n",
    "\n",
    "stream = speechsdk.AudioDataStream(result)\n",
    "# stream.save_to_wav_file(\"ssml_test_result.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure.ai.textanalytics in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure.ai.textanalytics) (1.27.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure.ai.textanalytics) (1.1.28)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure.ai.textanalytics) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure.ai.textanalytics) (4.6.3)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaharlyr\\appdata\\local\\miniconda3\\envs\\webapp\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure.ai.textanalytics) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure.ai.textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "ta_credential = AzureKeyCredential(subscription_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=\"https://cogn-cc-cds-nonprod.cognitiveservices.azure.com/\", \n",
    "            credential=ta_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polish'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"jestem Roman\"]\n",
    "response = text_analytics_client.detect_language(documents = documents)[0]\n",
    "response.primary_language.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.primary_language.iso6391_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process SSML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_voice_name(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        pattern = r\"\\\"ShortName\\\":\\\"([^\\\"]+)\\\"\"\n",
    "        match = re.search(pattern, file_content)\n",
    "        if match:\n",
    "            voice_name = match.group(1)\n",
    "            voice_name = voice_name.split(\"-\")[-1]\n",
    "            return voice_name\n",
    "        else:\n",
    "            raise Exception\n",
    "        \n",
    "        \n",
    "def generate_voice_configurations(base_folder):\n",
    "    voice_configurations = {}\n",
    "\n",
    "    base_path = Path(base_folder)\n",
    "    subfolders = [subfolder for subfolder in base_path.iterdir() if subfolder.is_dir()]\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        voice_configurations[subfolder.name] = {}\n",
    "\n",
    "        files = [file for file in subfolder.glob(\"*.txt\") if file.is_file()]\n",
    "\n",
    "        for file in files:\n",
    "            voice_name = get_voice_name(str(file))\n",
    "            voice_configurations[subfolder.name][voice_name] = file\n",
    "\n",
    "    return voice_configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "load_dotenv()\n",
    "\n",
    "base_folder = \"ssml_files\"\n",
    "voice_configurations = generate_voice_configurations(base_folder)\n",
    "# print(voice_configurations)\n",
    "\n",
    "# Configure Azure Speech Service\n",
    "subscription_key = os.getenv('SUBSCRIPTION_KEY')\n",
    "service_region = os.getenv('SERVICE_REGION')\n",
    "translator_endpoint = os.getenv('TRANSLATOR_ENDPOINT')\n",
    "text_analytics_endpoint = os.getenv('TEXT_ANALYTICS_ENDPOINT')\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=service_region)\n",
    "# speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "\n",
    "# Specify the output audio configuration\n",
    "output_file = \"temp_generated_result.mp3\"\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)\n",
    "\n",
    "# Create the speech synthesizer with the speech config and audio config\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang_code = \"fr\"\n",
    "selected_voice = \"DavisNeural\"\n",
    "\n",
    "# test_text = \"Où puis-je trouver un bon restaurant/café/la plage/le centre-ville?\"\n",
    "test_text = \"forget it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_ssml(ssml_string, new_text):\n",
    "    pattern1 = r\"<prosody([^>]*)>.*?<\\/prosody>\"\n",
    "    pattern2 = r\"<mstts:express-as([^>]*)>.*?<\\/mstts:express-as>\"\n",
    "    pattern3 = r\"<s />.*?<s />\"\n",
    "    pattern4 = r\"<voice([^>]*)>.*?</voice>\"\n",
    "\n",
    "    match1 = re.search(pattern1, ssml_string)\n",
    "    match2 = re.search(pattern2, ssml_string)\n",
    "    match3 = re.search(pattern3, ssml_string)\n",
    "    match4 = re.search(pattern4, ssml_string)\n",
    "    if match1: \n",
    "        return re.sub(pattern1, f\"<prosody\\\\1>{new_text}</prosody>\", ssml_string)\n",
    "    elif match2:\n",
    "        return re.sub(pattern2, f\"<mstts:express-as\\\\1>{new_text}</mstts:express-as>\", ssml_string)\n",
    "    elif match3:\n",
    "        return re.sub(pattern3, f\"<s />{new_text}<s />\", ssml_string)\n",
    "    elif match4:\n",
    "        return re.sub(pattern4, f\"<voice\\\\1>{new_text}</voice>\", ssml_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssml_string = \"\"\"\n",
    "\n",
    "<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"fr-FR\"><voice name=\"fr-FR-AlainNeural\"></voice></speak>\n",
    "\"\"\"\n",
    "ssml_string_modified = modify_ssml(ssml_string, \"what color is it?!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"fr-FR\"><voice name=\"fr-FR-AlainNeural\">what color is it?!</voice></speak>\\n'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssml_string_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized and saved to [temp_generated_result.mp3]\n"
     ]
    }
   ],
   "source": [
    "result = speech_synthesizer.speak_ssml(ssml_string_modified)\n",
    "\n",
    "# Check the synthesis result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized and saved to [{}]\".format(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': {'DavisNeural': WindowsPath('ssml_files/en/davis.txt'), 'GuyNeural': WindowsPath('ssml_files/en/guy.txt')}, 'es': {'IreneNeural': WindowsPath('ssml_files/es/irene.txt'), 'JorgeNeural': WindowsPath('ssml_files/es/jorge.txt')}, 'fr': {}, 'hi': {}}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def generate_voice_configurations(base_folder):\n",
    "    voice_configurations = {}\n",
    "\n",
    "    base_path = Path(base_folder)\n",
    "    subfolders = [subfolder for subfolder in base_path.iterdir() if subfolder.is_dir()]\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        voice_configurations[subfolder.name] = {}\n",
    "\n",
    "        files = [file for file in subfolder.glob(\"*.txt\") if file.is_file()]\n",
    "\n",
    "        for file in files:\n",
    "            voice_name = get_voice_name(str(file))\n",
    "            voice_configurations[subfolder.name][voice_name] = file\n",
    "\n",
    "    return voice_configurations\n",
    "\n",
    "base_folder = \"ssml_files\"\n",
    "voice_configurations = generate_voice_configurations(base_folder)\n",
    "print(voice_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = voice_configurations[\"en\"][\"DavisNeural\"].read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!--ID=B7267351-473F-409D-9765-754A8EBCDE05;Version=1|{\"VoiceNameToIdMapItems\":[{\"Id\":\"b5f86142-ce84-4483-8142-45db0d778add\",\"Name\":\"Microsoft Server Speech Text to Speech Voice (en-US, DavisNeural)\",\"ShortName\":\"en-US-DavisNeural\",\"Locale\":\"en-US\",\"VoiceType\":\"StandardVoice\"}]}-->\\n<!--ID=5B95B1CC-2C7B-494F-B746-CF22A0E779B7;Version=1|{\"Locales\":{\"en-US\":{\"AutoApplyCustomLexiconFiles\":[{}]},\"de-DE\":{\"AutoApplyCustomLexiconFiles\":[{}]},\"fr-FR\":{\"AutoApplyCustomLexiconFiles\":[{}]}}}-->\\n<!--ID=FCB40C2B-1F9F-4C26-B1A1-CF8E67BE07D1;Version=1|{\"Files\":{}}-->\\n<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"en-US\"><voice name=\"en-US-DavisNeural\"><s /><mstts:express-as style=\"whispering\" styledegree=\"1.1\"></mstts:express-as><s /></voice></speak>'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"ssml_files/es/irene.txt\", 'r') as file:\n",
    "#     x = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"ssml_files/en/davis.txt\", 'r') as file:\n",
    "    ssml_string_1 = file.read()\n",
    "\n",
    "with open(r\"ssml_files/en/guy.txt\", 'r') as file:\n",
    "    ssml_string_2 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_ssml_with_new_text(ssml_string, new_text):\n",
    "    pattern = r\"<prosody([^>]*)>.*?<\\/prosody>\"\n",
    "    match = re.search(pattern, ssml_string)\n",
    "    if match:\n",
    "        modified_ssml_string = re.sub(pattern, f\"<prosody\\\\1>{new_text}</prosody>\", ssml_string)\n",
    "        return modified_ssml_string\n",
    "    else:\n",
    "        pattern = r\"<mstts:express-as([^>]*)>.*?<\\/mstts:express-as>\"\n",
    "        modified_ssml_string = re.sub(pattern, f\"<mstts:express-as\\\\1>{new_text}</mstts:express-as>\", ssml_string)\n",
    "        return modified_ssml_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!--ID=B7267351-473F-409D-9765-754A8EBCDE05;Version=1|{\"VoiceNameToIdMapItems\":[{\"Id\":\"b5f86142-ce84-4483-8142-45db0d778add\",\"Name\":\"Microsoft Server Speech Text to Speech Voice (en-US, DavisNeural)\",\"ShortName\":\"en-US-DavisNeural\",\"Locale\":\"en-US\",\"VoiceType\":\"StandardVoice\"}]}-->\\n<!--ID=5B95B1CC-2C7B-494F-B746-CF22A0E779B7;Version=1|{\"Locales\":{\"en-US\":{\"AutoApplyCustomLexiconFiles\":[{}]},\"de-DE\":{\"AutoApplyCustomLexiconFiles\":[{}]},\"fr-FR\":{\"AutoApplyCustomLexiconFiles\":[{}]}}}-->\\n<!--ID=FCB40C2B-1F9F-4C26-B1A1-CF8E67BE07D1;Version=1|{\"Files\":{}}-->\\n<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"en-US\"><voice name=\"en-US-DavisNeural\"><s /><mstts:express-as style=\"whispering\" styledegree=\"1.1\"></mstts:express-as><s /></voice></speak>'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssml_string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modify_ssml(ssml_string_1, \"hello sweetie...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = speech_synthesizer.speak_ssml_async(y).get()\n",
    "\n",
    "stream = speechsdk.AudioDataStream(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Request the list of available voices\n",
    "# voices_result = speech_synthesizer.get_voices_async().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_lang_code = \"de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "voices_for_selected_lang = dict()\n",
    "for voice in voices_result.voices:\n",
    "    if voice.locale[:2] == selected_lang_code:\n",
    "        voices_for_selected_lang[voice.local_name] = voice.short_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es-MX\n",
      "Renata\n",
      "-\n",
      "es-MX-RenataNeural\n",
      "Microsoft Server Speech Text to Speech Voice (es-MX, RenataNeural)\n"
     ]
    }
   ],
   "source": [
    "# print(voices_result.voices[200].locale)\n",
    "# print(voices_result.voices[200].local_name)\n",
    "\n",
    "# print(\"-\")\n",
    "# print(voices_result.voices[200].short_name)\n",
    "# print(voices_result.voices[200].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receives a text from user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type some text that you want to speak...\n"
     ]
    }
   ],
   "source": [
    "print(\"Type some text that you want to speak...\")\n",
    "text = (\"Type some text that you want to speak...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesizes the received text to speech. The synthesized speech is expected to be heard on the speaker with below line executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello Bohdanko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = speech_synthesizer.speak_text_async(text).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks the synthesis result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized to speaker for text [Type some text that you want to speak...]\n"
     ]
    }
   ],
   "source": [
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized to speaker for text [{}]\".format(text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    print(\"Did you update the subscription info?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized and saved to [temp_generated_result.mp3]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "speech_key, service_region = ####\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "# Specify the output audio configuration\n",
    "output_file = \"temp_generated_result.mp3\"\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)\n",
    "\n",
    "# Create the speech synthesizer with the speech config and audio config\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "text = \"hello hello!\" # TEXT FROM INPUT FIELD\n",
    "\n",
    "# Synthesize the received text to speech and save it to the output file\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Check the synthesis result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized and saved to [{}]\".format(output_file))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    print(\"Did you update the subscription info?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.translation.document import DocumentTranslationClient\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "document_translation_client = DocumentTranslationClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, os, uuid, json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.core.exceptions import HttpResponseError\n",
    "# from azure.ai.translation.text import TextTranslationClient\n",
    "\n",
    "\n",
    "# try:\n",
    "#     text_translator = TextTranslationClient(endpoint=endpoint, credential=subscription_key)\n",
    "#     supported_languages = text_translator.get_languages()\n",
    "\n",
    "#     print(\"Connection to Azure Cognitive Services Translation successful!\")\n",
    "#     print(f\"Supported languages: {', '.join(supported_languages)}\")\n",
    "# except HttpResponseError as e:\n",
    "#     if e.error.code == \"InvalidRequest\":\n",
    "#         print(\"Azure Cognitive Services Translation resource does not exist.\")\n",
    "#     else:\n",
    "#         print(\"An error occurred while connecting to Azure Cognitive Services Translation.\")\n",
    "#     print(f\"Error details: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"translations\": [\n",
      "            {\n",
      "                \"text\": \"J’aimerais vraiment conduire votre voiture autour du pâté de maisons plusieurs fois!\",\n",
      "                \"to\": \"fr\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"Ngingathanda ngempela ukushayela imoto yakho emhlabeni block izikhathi ezimbalwa!\",\n",
      "                \"to\": \"zu\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests, uuid, json\n",
    "\n",
    "# Add your key and endpoint\n",
    "key = ####\n",
    "endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "\n",
    "# location, also known as region.\n",
    "# required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
    "location = \"canadacentral\"\n",
    "\n",
    "path = '/translate'\n",
    "constructed_url = endpoint + path\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'en',\n",
    "    'to': ['fr', 'zu']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    # location required if you're using a multi-service or regional (not global) resource.\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "# You can pass more than one object in body.\n",
    "body = [{\n",
    "    'text': 'I would really like to drive your car around the block a few times!'\n",
    "}]\n",
    "\n",
    "request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hola cómo estás?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "# Example translation request\n",
    "text_to_translate = 'Hello, how are you?'\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Region': location\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'en',\n",
    "    'to': 'es'\n",
    "}\n",
    "\n",
    "body = [{\n",
    "    'text': text_to_translate\n",
    "}]\n",
    "\n",
    "response = requests.post(f'{endpoint}/translate', headers=headers, params=params, json=body)\n",
    "translation = response.json()[0]['translations'][0]['text']\n",
    "\n",
    "print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, send_file\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import base64\n",
    "import docx\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure Speech Service\n",
    "subscription_key = os.getenv('SUBSCRIPTION_KEY')\n",
    "service_region = os.getenv('SERVICE_REGION')\n",
    "speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=service_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m translator_response \u001b[39m=\u001b[39m translator_request\u001b[39m.\u001b[39mjson()\n\u001b[0;32m     23\u001b[0m \u001b[39m# Retrieve the translation\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m translated_text \u001b[39m=\u001b[39m translator_response[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mtranslations\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Indicate that we want to translate and the API version (3.0) and the target language\n",
    "path = '/translate?api-version=3.0'\n",
    "# Add the target language parameter\n",
    "target_language_parameter = '&to=' + target_language\n",
    "# Create the full URL\n",
    "constructed_url = endpoint + path + target_language_parameter\n",
    "\n",
    "# Set up the header information, which includes our subscription key\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "# Create the body of the request with the text to be translated\n",
    "body = [{ 'text': original_text }]\n",
    "\n",
    "# Make the call using post\n",
    "translator_request = requests.post(constructed_url, headers=headers, json=body)\n",
    "# Retrieve the JSON response\n",
    "translator_response = translator_request.json()\n",
    "# Retrieve the translation\n",
    "translated_text = translator_response[0]['translations'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': '404', 'message': 'Resource not found'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"404\",\n",
      "        \"message\": \"Resource not found\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, uuid, json\n",
    "\n",
    "# Add your key and endpoint\n",
    "\n",
    "\n",
    "# location, also known as region.\n",
    "# required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
    "location = \"canadacentral\"\n",
    "\n",
    "path = '/translate'\n",
    "constructed_url = endpoint + path\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'en',\n",
    "    'to': ['fr', 'zu']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    # location required if you're using a multi-service or regional (not global) resource.\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "# You can pass more than one object in body.\n",
    "body = [{\n",
    "    'text': 'I would really like to drive your car around the block a few times!'\n",
    "}]\n",
    "\n",
    "request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_with_punctuation_characters(text):\n",
    "    # Regular expression to match URLs\n",
    "    url_pattern = r'((?:http://|https://|www\\.)\\S+|(?:\\w+\\.\\w+/\\S+))'\n",
    "    \n",
    "    # Find all URL matches in the text\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    # Replace each URL with the enhanced format and add a comma after the URL\n",
    "    for url in urls:\n",
    "        enhanced_url = re.sub(r'/', ',/', url)\n",
    "        text = text.replace(url, enhanced_url + \",\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"visit wsib.ca/onlineservices to find all the ways to work with us online, 24/7.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visit wsib.ca,/onlineservices, to find all the ways to work with us online, 24/7.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_with_punctuation_characters(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call 1-866-797-0000, or 9-1-1. Visit wsib.ca,/onlineservices, to find all the ways to work with us online, 24/7. W S IB is great.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def enhance_with_punctuation_characters(text):\n",
    "    # Replace mobile numbers with spaces between them with dashes\n",
    "    text = re.sub(r'\\b1\\s\\d{3}\\s\\d{3}\\s\\d{4}\\b', lambda match: match.group().replace(\" \", \"-\"), text)\n",
    "    \n",
    "    # Replace Canadian governmental short numbers like \"911\" to \"9-1-1\"\n",
    "    text = re.sub(r'\\b911\\b', '9-1-1', text)\n",
    "\n",
    "    # Regular expression to match URLs\n",
    "    url_pattern = r'((?:http://|https://|www\\.)\\S+|(?:\\w+\\.\\w+/\\S+))'\n",
    "    \n",
    "    # Find all URL matches in the text\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    # Replace each URL with the enhanced format and add a comma after the URL\n",
    "    for url in urls:\n",
    "        enhanced_url = re.sub(r'/', ',/', url)\n",
    "        text = text.replace(url, enhanced_url + \",\")\n",
    "    \n",
    "    # Replace \"WSIB\" with \"W S IB\"\n",
    "    text = text.replace(\"WSIB\", \"W S IB\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "text = \"Call 1 866 797 0000, or 911. Visit wsib.ca/onlineservices to find all the ways to work with us online, 24/7. WSIB is great.\"\n",
    "enhanced_text = enhance_with_punctuation_characters(text)\n",
    "print(enhanced_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appelez Télésanté Ontario au <break strength=\"x-weak\"/> 1, <break strength=\"x-weak\"/> 8, <break strength=\"x-weak\"/> 6, <break strength=\"x-weak\"/> 6, <break strength=\"x-weak\"/> 7, <break strength=\"x-weak\"/> 9, <break strength=\"x-weak\"/> 7, <break strength=\"x-weak\"/> 0, <break strength=\"x-weak\"/> 0, <break strength=\"x-weak\"/> 0, <break strength=\"x-weak\"/> 0. Dans une situation d’urgence, composez toujours le 911.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"appelez Télésanté Ontario au 1-866-797-0000. Dans une situation d’urgence, composez toujours le 911.\"\n",
    "\n",
    "# Step 1: Find and extract phone number patterns\n",
    "matches = re.findall(r'\\b(\\d)-?(\\d{3})-?(\\d{3})-?(\\d{4})\\b|\\b(\\d) (\\d{3}) (\\d{3}) (\\d{4})\\b', text)\n",
    "\n",
    "# Step 2: Combine the digits to form a single number without spaces or dashes\n",
    "numbers = [''.join(match[:4]) if match[0] else ''.join(match[4:]) for match in matches]\n",
    "\n",
    "# Step 3: Format the resulting numbers with breaks\n",
    "formatted_numbers = ', '.join([f'<break strength=\"x-weak\"/> {digit}' for number in numbers for digit in number])\n",
    "\n",
    "# Replace the phone numbers in the original text with the formatted version\n",
    "formatted_text = re.sub(r'\\b(\\d)-?(\\d{3})-?(\\d{3})-?(\\d{4})\\b|\\b(\\d) (\\d{3}) (\\d{3}) (\\d{4})\\b', formatted_numbers, text)\n",
    "\n",
    "# Output the result with enhanced numbers\n",
    "print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
